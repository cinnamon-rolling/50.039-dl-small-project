{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39264bitvenva4d00fc0239a41138288b72205840686",
   "display_name": "Python 3.9.2 64-bit ('venv')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Small Project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Architecture\n",
    "\n",
    "Data\n",
    "|\n",
    "DataLoader\n",
    "|\n",
    "Resize (224x224)\n",
    "|\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Inspecting Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset directory: dataset/train/normal          \tCount: 1341\nDataset directory: dataset/train/infected/non-covid\tCount: 2530\nDataset directory: dataset/train/infected/covid  \tCount: 1345\nDataset directory: dataset/val/normal            \tCount: 8\nDataset directory: dataset/val/infected/non-covid\tCount: 8\nDataset directory: dataset/val/infected/covid    \tCount: 9\nDataset directory: dataset/test/normal           \tCount: 234\nDataset directory: dataset/test/infected/non-covid\tCount: 242\nDataset directory: dataset/test/infected/covid   \tCount: 139\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"dataset\"):\n",
    "    if len(files) > 0:\n",
    "        print(\"Dataset directory: {:30}\\tCount: {}\".format(root, len(files)))"
   ]
  },
  {
   "source": [
    "## DataLoader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "source": [
    "### Global Dataset Object"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Lungs Dataset that can be constructed into Train, Test, Validation dataset respectively, and select a Dataset (Normal-Infected or Covid-NonCovid) to use, based on the binary classifier implementation.\n",
    "class LungDataset(Dataset):\n",
    "    def __init__(self, group, mode=0):\n",
    "\n",
    "        # Select the mode for Dataset\n",
    "        if mode not in [0, 1]:\n",
    "            raise ValueError(\"Please input a mode as integers: 0: [Normal-Infected], 1: [Covid-NonCovid]\")\n",
    "        self.mode = mode\n",
    "\n",
    "        # All images are of size 150 x 150\n",
    "        self.img_size = (150, 150)\n",
    "        \n",
    "        # Only two classes will be considered here (normal and infected)\n",
    "        self.classes = {0: 'normal', 1: 'infected_covid', 2: 'infected_non_covid'}\n",
    "        \n",
    "        # The dataset has been split in training, testing and validation datasets\n",
    "        self.groups = [group]\n",
    "        \n",
    "        # Number of images in each part of the dataset\n",
    "        self.dataset_numbers = {'train_normal': 1341,\\\n",
    "                                'train_infected_covid': 1345,\\\n",
    "                                'train_infected_non_covid': 2530,\\\n",
    "                                'val_normal': 8,\\\n",
    "                                'val_infected_covid': 9,\\\n",
    "                                'val_infected_non_covid': 8,\\\n",
    "                                'test_normal': 234,\\\n",
    "                                'test_infected_covid': 139,\\\n",
    "                                'test_infected_non_covid': 242}\n",
    "        \n",
    "    def get_dataset_path(self, _class):\n",
    "        sub_path = None\n",
    "        group = self.groups[0]\n",
    "        if _class == self.classes[1]:\n",
    "            sub_path = os.path.join(\"infected\", \"covid\")\n",
    "        elif _class == self.classes[2]:\n",
    "            sub_path = os.path.join(\"infected\", \"non-covid\")\n",
    "        else:\n",
    "            sub_path = \"normal\"\n",
    "        return os.path.join(\"dataset\", group, sub_path)\n",
    "\n",
    "    def filter_dataset_numbers(self):\n",
    "        filtered_dataset_numbers_map = dict()\n",
    "        for key, value in self.dataset_numbers.items():\n",
    "            if self.groups[0] in key:\n",
    "                filtered_dataset_numbers_map[key] = value\n",
    "        return filtered_dataset_numbers_map\n",
    "\n",
    "    def describe(self):\n",
    "        if self.mode == 0:\n",
    "            mode_str = \"Normal-Infected\"\n",
    "        elif self.mode == 1:\n",
    "            mode_str = \"Covid-NonCovid\"\n",
    "        filtered_dataset_numbers_map = self.filter_dataset_numbers()\n",
    "        # Generate description\n",
    "        msg = \"This is the Lung {} {} Dataset used for the Small Project Demo in the 50.039 Deep Learning class\".format(self.groups[0].upper(), mode_str)\n",
    "        msg += \" in Feb-March 2021. \\n\"\n",
    "        msg += \"It contains a total of {} images, \".format(len(self))\n",
    "        msg += \"of size {} by {}.\\n\".format(self.img_size[0], self.img_size[1])\n",
    "        msg += \"Images have been split in three groups: training, testing and validation sets.\\n\"\n",
    "        msg += \"The images are stored in the following locations \"\n",
    "        msg += \"and each one contains the following number of images:\\n\"\n",
    "        for group in self.groups:\n",
    "            for _class in self.classes.values():\n",
    "                label = \"{}_{}\".format(group, _class)\n",
    "                path = self.get_dataset_path(_class)\n",
    "                if self.mode == 1 and \"normal\" not in _class:\n",
    "                    msg += \" - {}, in folder {}: {} images.\\n\".format(label, path, filtered_dataset_numbers_map[label])\n",
    "                elif self.mode == 0:\n",
    "                    msg += \" - {}, in folder {}: {} images.\\n\".format(label, path, filtered_dataset_numbers_map[label])\n",
    "        print(msg)\n",
    "    \n",
    "    def open_img(self, _class, index):\n",
    "        group = self.groups[0]\n",
    "        if _class not in self.classes.values():\n",
    "            raise ValueError(\"Input class not found! Please input: {}. Got: {}\".format(list(self.classes.values()), _class))\n",
    "        max_val = self.dataset_numbers['{}_{}'.format(group, _class)]\n",
    "        if index < 0 or index >= max_val:\n",
    "            raise ValueError(\"Index out of range! Should be (0 ~ {}) but got {}\".format(max_val-1, index))\n",
    "        path_to_file = os.path.join(self.get_dataset_path(_class), \"{}.jpg\".format(index))\n",
    "        with open(path_to_file, 'rb') as f:\n",
    "            im = np.asarray(Image.open(f)) / 255    # Normalize\n",
    "        f.close()\n",
    "        return im\n",
    "    \n",
    "    def show_img(self, _class, index):\n",
    "        # Open image\n",
    "        im = self.open_img(_class, index)\n",
    "        \n",
    "        # Display\n",
    "        plt.imshow(im)\n",
    "\n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for key, item in self.dataset_numbers.items():\n",
    "            if self.groups[0] in key:\n",
    "                if self.mode == 0:\n",
    "                    length += item\n",
    "                elif self.mode == 1 and \"normal\" not in key:\n",
    "                    length += item\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filtered_dataset_numbers_map = self.filter_dataset_numbers()\n",
    "        if self.mode == 0:\n",
    "            first_val = int(list(filtered_dataset_numbers_map.values())[0])\n",
    "            second_val = int(list(filtered_dataset_numbers_map.values())[1])\n",
    "            if index < first_val:\n",
    "                _class = 'normal'\n",
    "                label = torch.Tensor([1, 0])\n",
    "            elif first_val <= index < first_val + second_val:\n",
    "                _class = 'infected_covid'\n",
    "                index = index - first_val\n",
    "                label = torch.Tensor([0, 1])\n",
    "            else:\n",
    "                _class = 'infected_non_covid'\n",
    "                index = index - first_val - second_val\n",
    "                label = torch.Tensor([0, 1])\n",
    "        elif self.mode == 1:\n",
    "            first_val = int(list(filtered_dataset_numbers_map.values())[1])\n",
    "            if index < first_val:\n",
    "                _class = 'infected_covid'\n",
    "                label = torch.Tensor([1, 0])\n",
    "            else:\n",
    "                _class = 'infected_non_covid'\n",
    "                index = index - first_val\n",
    "                label = torch.Tensor([0, 1])\n",
    "        im = self.open_img(_class, index)\n",
    "        im = transforms.functional.to_tensor(np.array(im)).float()\n",
    "        return im, label\n"
   ]
  },
  {
   "source": [
    "#### To get the training set for Normal-Infected:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This is the Lung TRAIN Normal-Infected Dataset used for the Small Project Demo in the 50.039 Deep Learning class in Feb-March 2021. \nIt contains a total of 5216 images, of size 150 by 150.\nImages have been split in three groups: training, testing and validation sets.\nThe images are stored in the following locations and each one contains the following number of images:\n - train_normal, in folder dataset/train/normal: 1341 images.\n - train_infected_covid, in folder dataset/train/infected/covid: 1345 images.\n - train_infected_non_covid, in folder dataset/train/infected/non-covid: 2530 images.\n\nThis train set contains 5216 images in total.\ntensor([[[0.0275, 0.0510, 0.0667,  ..., 0.0980, 0.1333, 0.1647],\n         [0.0510, 0.0431, 0.0314,  ..., 0.1020, 0.1255, 0.1412],\n         [0.0392, 0.0275, 0.0157,  ..., 0.0902, 0.1098, 0.1137],\n         ...,\n         [0.0471, 0.0275, 0.0235,  ..., 0.0510, 0.0627, 0.0784],\n         [0.0392, 0.0275, 0.0314,  ..., 0.0510, 0.0627, 0.0784],\n         [0.0314, 0.0235, 0.0314,  ..., 0.0471, 0.0471, 0.0510]]])\n"
     ]
    }
   ],
   "source": [
    "trainset = LungDataset(group=\"train\", mode=0)\n",
    "trainset.describe()\n",
    "print(\"This train set contains {} images in total.\".format(len(trainset)))\n",
    "im, label = trainset[5215]\n",
    "print(im)"
   ]
  },
  {
   "source": [
    "#### To get the testing set for Covid-NonCovid:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This is the Lung TEST Covid-NonCovid Dataset used for the Small Project Demo in the 50.039 Deep Learning class in Feb-March 2021. \nIt contains a total of 381 images, of size 150 by 150.\nImages have been split in three groups: training, testing and validation sets.\nThe images are stored in the following locations and each one contains the following number of images:\n - test_infected_covid, in folder dataset/test/infected/covid: 139 images.\n - test_infected_non_covid, in folder dataset/test/infected/non-covid: 242 images.\n\nThis test set contains 381 images in total.\ntensor([[[0.0471, 0.0588, 0.0784,  ..., 0.3020, 0.2941, 0.2902],\n         [0.0627, 0.0824, 0.1020,  ..., 0.3255, 0.3176, 0.3098],\n         [0.0941, 0.1137, 0.1451,  ..., 0.3333, 0.3294, 0.3216],\n         ...,\n         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "testset = LungDataset(group=\"test\", mode=1)\n",
    "testset.describe()\n",
    "print(\"This test set contains {} images in total.\".format(len(testset)))\n",
    "im, label = testset[380]\n",
    "print(im)"
   ]
  },
  {
   "source": [
    "### Global DataLoader Object"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Create DataLoaders for Normal-Infected"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fb1c2595520> <torch.utils.data.dataloader.DataLoader object at 0x7fb1c2585640> <torch.utils.data.dataloader.DataLoader object at 0x7fb1c2595880>\n"
     ]
    }
   ],
   "source": [
    "trainset_normal_infected = LungDataset(group=\"train\", mode=0)\n",
    "testset_nomral_infected = LungDataset(group=\"test\", mode=0)\n",
    "valset_normal_infected = LungDataset(group=\"val\", mode=0)\n",
    "train_loader = DataLoader(trainset_normal_infected, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(testset_nomral_infected, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(valset_normal_infected, batch_size=4, shuffle=True)\n",
    "print(train_loader, test_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1304\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in enumerate(train_loader):\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "source": [
    "#### Create DataLoaders for Covid-NonCovid"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fb1c25dbca0> <torch.utils.data.dataloader.DataLoader object at 0x7fb1c257c970> <torch.utils.data.dataloader.DataLoader object at 0x7fb1c257caf0>\n"
     ]
    }
   ],
   "source": [
    "trainset_covid_noncovid = LungDataset(group=\"train\", mode=1)\n",
    "testset_covid_noncovid = LungDataset(group=\"test\", mode=1)\n",
    "valset_covid_noncovid = LungDataset(group=\"val\", mode=1)\n",
    "train_loader = DataLoader(trainset_covid_noncovid, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(testset_covid_noncovid, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(valset_covid_noncovid, batch_size=4, shuffle=True)\n",
    "print(train_loader, test_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "969\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in enumerate(train_loader):\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}